{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Shipping Forecast Bot Prototype",
   "id": "e78c59b1b9bcae28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preinstall the required packages",
   "id": "2414fee7ca43539e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T20:28:05.403867Z",
     "start_time": "2025-03-12T20:28:04.364242Z"
    }
   },
   "source": "!pip install requests beautifulsoup4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (2.32.3)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.9/site-packages (4.13.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests) (2025.1.31)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4) (2.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./venv/lib/python3.9/site-packages (from beautifulsoup4) (4.12.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define the data class for the forecast\n",
    "\n",
    "This data class services for the data exchange between the different sources and the report generator."
   ],
   "id": "9d35c1bd10a956ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:28:09.349954Z",
     "start_time": "2025-03-12T20:28:09.342462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Forecast:\n",
    "    source_id: int\n",
    "    source_name: str\n",
    "    url: str\n",
    "    publication_time: str\n",
    "    synoptic_info: str\n",
    "    warnings: List[dict]\n",
    "    forecast_details: dict\n",
    "\n",
    "    def display_info(self):\n",
    "        return f\"Forecast published at {self.publication_time} on {self.source_name}\"\n",
    "\n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: dict):\n",
    "        return cls(\n",
    "            source_id=data[\"source_id\"],\n",
    "            source_name=data[\"source_name\"],\n",
    "            url=data[\"url\"],\n",
    "            publication_time=data[\"publication_time\"],\n",
    "            synoptic_info=data[\"synoptic_info\"],\n",
    "            warnings=data[\"warnings\"],\n",
    "            forecast_details=data[\"forecast_details\"]\n",
    "        )\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Forecast):\n",
    "            return False\n",
    "        return self.to_dict() == other.to_dict()\n"
   ],
   "id": "89587bd476ec2771",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define the report generator class\n",
    "\n",
    "The report generator class takes a full forecast from a source and list of subscribed areas for generation of a personalized human-readable report."
   ],
   "id": "ecb09504f77cc261"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:36:07.974394Z",
     "start_time": "2025-03-12T20:36:07.963278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReportGenerator:\n",
    "\n",
    "    def __init__(self, forecast: Forecast):\n",
    "        self.forecast = forecast\n",
    "\n",
    "    def generate_report(self, subscribed_areas) -> str:\n",
    "        report_lines = [\n",
    "            f\"Issued by {self.forecast.source_name}\\n\",\n",
    "            f\"Shipping Forecast Publication Time: {self.forecast.publication_time}\\n\",\n",
    "            f\"General Synoptic Information: {self.forecast.synoptic_info}\\n\"\n",
    "        ]\n",
    "\n",
    "        # Warnings: include warnings only if any of the affected areas contain one of the user's subscribed areas.\n",
    "        relevant_warnings = []\n",
    "        for warning in self.forecast.warnings:\n",
    "            for warning_area in warning.get(\"areas\", []):\n",
    "                for area in subscribed_areas:\n",
    "                    if area.lower() in warning_area.lower():\n",
    "                        relevant_warnings.append(warning)\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "\n",
    "        if relevant_warnings:\n",
    "            report_lines.append(\"Warnings:\")\n",
    "            for warning in relevant_warnings:\n",
    "                report_lines.append(f\"  Warning Type: {warning.get('warning_type', 'N/A')}\")\n",
    "                report_lines.append(\"  Affected Areas:\")\n",
    "                for w_area in warning.get(\"areas\", []):\n",
    "                    report_lines.append(f\"    - {w_area}\")\n",
    "                report_lines.append(\"\")  # blank line for readability\n",
    "        else:\n",
    "            report_lines.append(\"No warnings for your subscribed areas.\\n\")\n",
    "\n",
    "        # Forecasts for each of the user's areas\n",
    "        report_lines.append(\"Forecasts for your subscribed areas:\")\n",
    "        for user_area in subscribed_areas:\n",
    "            found = False\n",
    "            for region, forecast in self.forecast.forecast_details.items():\n",
    "                # Check if the user's area is present in the forecast region name (case-insensitive)\n",
    "                if user_area.lower() in region.lower():\n",
    "                    report_lines.append(f\"{region}:\")\n",
    "                    report_lines.append(forecast)\n",
    "                    report_lines.append(\"\")  # add a blank line between regions\n",
    "                    found = True\n",
    "            if not found:\n",
    "                report_lines.append(f\"{user_area}: Forecast not found.\\n\")\n",
    "\n",
    "        report_lines.append(f\"Source: {self.forecast.url}\\n\")\n",
    "        return \"\\n\".join(report_lines)"
   ],
   "id": "e0330860e1b30e4d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define the DWDSource class\n",
    "\n",
    "It's one of the sources for the forecast data. It fetches the forecast from the German Weather Service (DWD) website."
   ],
   "id": "6bc43634a6748d90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:28:18.660369Z",
     "start_time": "2025-03-12T20:28:18.497033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import re\n",
    "\n",
    "class DWDSource:\n",
    "\n",
    "    def __init__(self, url=\"https://www.dwd.de/EN/ourservices/seewetternordostseeen/seewetternordostsee.html\"):\n",
    "        # Name of the source\n",
    "        self.id = 1\n",
    "        self.name = \"DWD Marine\"\n",
    "        # URL of the web page with forecasts from the German Weather Service\n",
    "        self.url = url\n",
    "        # Send a GET request to fetch the page content\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "        }\n",
    "        self.response = requests.get(url, headers=headers)\n",
    "        # Check if the request was successful\n",
    "        if self.response.status_code != 200:\n",
    "            raise ValueError(f\"Failed to download the page. Status code: {self.response.status_code}\")\n",
    "\n",
    "    def get_forecast(self) -> Forecast:\n",
    "        # Get the HTML content\n",
    "        html_content = self.response.text\n",
    "        # Parse the full HTML document\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        # Find the <pre> tag which contains the bulletin text\n",
    "        pre_tag = soup.find(\"pre\")\n",
    "        if not pre_tag:\n",
    "            raise ValueError(\"No <pre> tag found in the HTML.\")\n",
    "        # Get the plain text (for publication time, synoptic info, and warnings)\n",
    "        pre_text = pre_tag.get_text(separator=\"\\n\")\n",
    "        # Also keep the HTML of the pre tag to leverage the bold (<B>) tags for forecast areas.\n",
    "        pre_html = str(pre_tag)\n",
    "        pre_soup = BeautifulSoup(pre_html, \"html.parser\")\n",
    "        # --- 1. Extract Publication Time ---\n",
    "        # Look for a date/time pattern like \"10.03.2025, 15.36 UTC\"\n",
    "        pub_time_match = re.search(r\"(\\d{2}\\.\\d{2}\\.\\d{4},\\s*\\d{2}\\.\\d{2}\\s*UTC)\", pre_text)\n",
    "        publication_time = pub_time_match.group(1) if pub_time_match else \"Not found\"\n",
    "        # --- 2. Extract General Synoptic Information ---\n",
    "        # We look for the line after the bold header \"General synoptic situation\"\n",
    "        synoptic_info_lines = []\n",
    "        lines = pre_text.splitlines()\n",
    "        synoptic_flag = False\n",
    "        for line in lines:\n",
    "            if \"general synoptic situation\" in line.lower():\n",
    "                synoptic_flag = True\n",
    "                continue\n",
    "            if synoptic_flag:\n",
    "                # Stop if we hit a blank line or a line that likely begins a new section (e.g. warnings)\n",
    "                if line.strip().lower().startswith(\"forecast valid\") or line.strip().lower().startswith(\"until\"):\n",
    "                    break\n",
    "                synoptic_info_lines.append(line.strip())\n",
    "        synoptic_info = \" \".join(synoptic_info_lines)\n",
    "        # --- 3. Extract Warnings Information (e.g. gales, strong winds) ---\n",
    "        # The warnings are given in lines that start with \"until ... in the following forecast areas ... are expected:\"\n",
    "        warnings = []\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            line = lines[i].strip()\n",
    "            # Check for a warning header line using a case-insensitive match\n",
    "            if line.lower().startswith(\"until\"):\n",
    "                # Persist the valid period and the warning type\n",
    "                warning_type = line\n",
    "                if lines[i+1].strip().lower().endswith(\"expected:\"):\n",
    "                    i += 1\n",
    "                    line = lines[i].strip()\n",
    "                    warning_type += \" \" + line\n",
    "                if line.lower().endswith(\"expected:\"):\n",
    "                    # Collect subsequent lines as warning areas until a blank line or another section starts\n",
    "                    warning_areas = []\n",
    "                    i += 1\n",
    "                    while i < len(lines):\n",
    "                        next_line = lines[i].strip()\n",
    "                        next_line_lower = next_line.lower()\n",
    "                        if next_line == \"\" or next_line_lower.startswith(\"until\") or next_line.startswith(\"<B>\"):\n",
    "                            break\n",
    "                        if \"utsire\" in next_line_lower:\n",
    "                            next_line = next_line_lower.replace(\"utsire\", \"utsira\")\n",
    "                        warning_areas.append(next_line)\n",
    "                        i += 1\n",
    "\n",
    "                    warnings.append({\n",
    "                        \"warning_type\": warning_type,\n",
    "                        \"areas\": warning_areas\n",
    "                    })\n",
    "            else:\n",
    "                i += 1\n",
    "        # --- 4. Extract Forecast Details for Each Region ---\n",
    "        # We only consider forecast areas that are marked with bold (<B>) tags,\n",
    "        # and skip any sections related to the outlook forecast.\n",
    "        forecast_header = pre_soup.find(lambda tag: tag.name == \"b\" and \"forecast valid until\" in tag.get_text().lower())\n",
    "        forecast_details = {}\n",
    "        if forecast_header:\n",
    "            # Iterate over all <b> tags that come after the forecast header.\n",
    "            for bold_tag in forecast_header.find_all_next(\"b\"):\n",
    "                bold_text = bold_tag.get_text(strip=True)\n",
    "                # Skip any forecast section that is part of the outlook\n",
    "                if \"outlook\" in bold_text.lower():\n",
    "                    break\n",
    "                # Process only forecast areas: they should end with a colon (e.g., \"German Bight:\")\n",
    "                if not bold_text.endswith(\":\"):\n",
    "                    continue\n",
    "                region = bold_text[:-1].strip()  # Remove the trailing colon\n",
    "\n",
    "                # To avoid duplicates, skip if the region is already present.\n",
    "                if region in forecast_details:\n",
    "                    continue\n",
    "\n",
    "                # Collect all following text (from sibling nodes) until the next bold tag is encountered.\n",
    "                forecast_info = \"\"\n",
    "                for sibling in bold_tag.next_siblings:\n",
    "                    # Stop at the next bold tag, which indicates the start of the next forecast area.\n",
    "                    if getattr(sibling, \"name\", None) == \"b\":\n",
    "                        break\n",
    "                    if isinstance(sibling, NavigableString):\n",
    "                        forecast_info += sibling.strip() + \" \"\n",
    "                    else:\n",
    "                        forecast_info += sibling.get_text(\" \", strip=True) + \" \"\n",
    "                forecast_details[region] = forecast_info.strip()\n",
    "        # return results as a Forecast object\n",
    "        return Forecast(\n",
    "            source_id=self.id,\n",
    "            source_name=self.name,\n",
    "            url=self.url,\n",
    "            publication_time=publication_time,\n",
    "            synoptic_info=synoptic_info,\n",
    "            warnings=warnings,\n",
    "            forecast_details=forecast_details\n",
    "        )"
   ],
   "id": "ab1afbca192ab028",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Storage class",
   "id": "32d6bbc411eb32fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:28:23.060886Z",
     "start_time": "2025-03-12T20:28:23.053377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from typing import List\n",
    "\n",
    "class CloudflareD1Storage:\n",
    "    \"\"\"\n",
    "    Tables:\n",
    "    CREATE TABLE areas ( area_id INTEGER PRIMARY KEY, area_name TEXT NOT NULL, source_id INTEGER NOT NULL );\n",
    "    CREATE TABLE sources ( source_id INTEGER PRIMARY KEY, source_name TEXT NOT NULL );\n",
    "    CREATE TABLE subscriptions ( chat_id INTEGER NOT NULL, source_id INTEGER NOT NULL, area_id INTEGER NOT NULL, PRIMARY KEY (chat_id, source_id, area_id) );\n",
    "\n",
    "    Indexes:\n",
    "    CREATE INDEX idx_subscriptions_source_chat ON subscriptions(source_id, chat_id);\n",
    "    CREATE INDEX idx_subscriptions_chat_id ON subscriptions(chat_id);\n",
    "    CREATE INDEX idx_area_source ON areas(source_id);\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cloudflare_account: str, cloudflare_database: str, cloudflare_token: str):\n",
    "        self.token = cloudflare_token\n",
    "        self.url = f\"https://api.cloudflare.com/client/v4/accounts/{cloudflare_account}/d1/database/{cloudflare_database}/query\"\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {cloudflare_token}\",\n",
    "        }\n",
    "\n",
    "    def _sql(self, sql: str):\n",
    "        response = requests.post(self.url, headers=self.headers, json={\"sql\": sql})\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Failed to perform the sql request. Status code: {response.status_code}. SQL: {sql}\")\n",
    "        return response.json().get(\"result\")[0].get(\"results\")\n",
    "\n",
    "    def get_subscriptions(self, source_id: int) -> dict[int, List[int]]:\n",
    "        response = self._sql(f\"\"\"\n",
    "            SELECT chat_id, GROUP_CONCAT(area_id, ',') AS area_ids\n",
    "            FROM subscriptions\n",
    "            WHERE source_id={source_id}\n",
    "            GROUP BY chat_id;\n",
    "        \"\"\")\n",
    "        return {int(row[\"chat_id\"]) : [int(id) for id in row[\"area_ids\"].split(\",\")] for row in response}\n",
    "\n",
    "    def get_dictionary(self, source_id: int) -> dict:\n",
    "        response = self._sql(f\"SELECT area_id, area_name FROM areas WHERE source_id={source_id};\")\n",
    "        return {int(row[\"area_id\"]): row[\"area_name\"] for row in response}\n",
    "\n",
    "    def drop_users(self, chat_ids: List[int]):\n",
    "        sql_ids = \", \".join(chat_ids)\n",
    "        self._sql(f\"DELETE FROM subscriptions WHERE chat_id IN ({sql_ids});\")"
   ],
   "id": "95182c06dfcff2fc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define the ForecastNotifier class\n",
    "\n",
    "The ForecastNotifier class is responsible for sending the generated report to the users via a messaging service."
   ],
   "id": "55053032e5240f30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:28:33.151591Z",
     "start_time": "2025-03-12T20:28:33.140177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ForecastNotifier:\n",
    "\n",
    "    def __init__(self, forecast: Forecast, storage: CloudflareD1Storage, tg_token: str):\n",
    "        self.forecast = forecast\n",
    "        self.storage = storage\n",
    "        self.tg_token = tg_token\n",
    "\n",
    "    def notify(self):\n",
    "        # Get the subscriptions for the current source\n",
    "        areas_dict = storage.get_dictionary(self.forecast.source_id)\n",
    "        user_subscriptions = { chat_id : [areas_dict.get(id) for id in area_ids] for chat_id, area_ids in storage.get_subscriptions(self.forecast.source_id).items() }\n",
    "        # Generate the report\n",
    "        report_generator = ReportGenerator(self.forecast)\n",
    "        failed_chat_ids = []\n",
    "        for chat_id, subscribed_areas in user_subscriptions.items():\n",
    "            report = report_generator.generate_report(subscribed_areas)\n",
    "            telegram_send_url = f\"https://api.telegram.org/bot{self.tg_token}/sendMessage?chat_id={chat_id}&text={report}\"\n",
    "            try:\n",
    "                response = requests.get(telegram_send_url).json()\n",
    "                if not response[\"ok\"]:\n",
    "                    failed_chat_ids.append(chat_id)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to send message to {chat_id}: {e}\")\n",
    "        # Drop the users with failed notifications\n",
    "        if len(failed_chat_ids) > 0:\n",
    "            storage.drop_users(failed_chat_ids)"
   ],
   "id": "994f5a65de2d5e6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test the pipeline",
   "id": "1da6ed65c6eb98d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:32:58.006642Z",
     "start_time": "2025-03-12T20:32:57.587529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "forecast = DWDSource().get_forecast()\n",
    "print(forecast)"
   ],
   "id": "ac91179866afaabc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast(source_id=1, source_name='DWD', url='https://www.dwd.de/EN/ourservices/seewetternordostseeen/seewetternordostsee.html', publication_time='12.03.2025, 16.51 UTC', synoptic_info=' A belt of low-pressure 998 between Barents-Sea, southern Baltic States and central North-Sea with an embedded low 996 Denmark is slowly filling up. At the same time, another low 993 Alpes is deepening, while moving northeast towards Lithuania. A shallow high 1009 North-Scandinavia is continuously shifting east. Another high 1025 Irminger-Sea with a connected ridge 1010 towards Bay of Biscay weakens somewhat.   ', warnings=[{'warning_type': 'until thursday evening in the following forecast areas strong winds are expected:', 'areas': ['german bight', 'fisher', 'viking', 'skagerrak', 'southeastern baltic', 'central baltic']}], forecast_details={'German Bight': 'northwesterly winds 4 to 5, locally 6, at times shower \\nsqualls, sea increasing 3 meter.', 'Southwestern North Sea': 'northerly winds 4 to 5, at times shower squalls, sea \\nhumber 2,5 meter.', 'Fisher': 'northeast 5 to 6, decreasing 4, at times shower squalls, \\nsea first 3 meter.', 'Dogger': 'north to northeast 4 to 5, later decreasing a little, at \\ntimes shower squalls, sea 2,5 meter.', 'Forties': 'north about 5, decreasing 4, sea 3 meter.', 'Viking': 'north to northeast 5 to 6, decreasing 4, at times shower \\nsqualls, sea 3 meter.', 'Utsira': 'utsire:\\nnorth to northeast 4 to 5, locally snow squalls, sea \\nfirst 2,5 meter.', 'Skagerrak': 'northeast 5 to 6, decreasing 4, moderate snow, sea 2 \\nmeter.', 'Kattegat': 'southeasterly winds 3 to 4, shifting northeast, at times \\nshower squalls, sea 1 meter.', 'Belts and Sound': 'first southwest 3, otherwise light and variable winds, \\nsea 0,5 meter.', 'Western Baltic': 'first southwest 3, otherwise light and variable winds, at \\ntimes coastal fog patches, sea 0,5 meter.', 'Southern Baltic': 'light and variable winds, shifting northeast, increasing \\n4 to 5, at times coastal fog patches, sea later 1,5 meter.', 'Boddengewaesser East': 'light and variable winds, shifting east later and \\nincreasing 3, at times coastal fog patches, sea 0,5 meter.', 'Southeastern Baltic': 'light and variable winds, shifting north to northeast, \\nincreasing 5 to 6, at times shower squalls, sea later 2 \\nmeter.', 'Central Baltic': 'first variable directions 2 to 4, otherwise light and \\nvariable winds, later north to northeast 5 to 6, locally \\nsnow squalls, sea later 2 meter.', 'Northern Baltic': 'northeast 4 to 5, shifting north, increasing a little, \\nmoderate snow, sea increasing 1,5 meter.', 'Gulf of Riga': 'southerly winds 3, veering north, later increasing 5, sea \\nlater 1 meter.', 'English Channel western part': 'north 3 to 4, for a time increasing 5, shifting \\nnortheast, at times shower squalls, sea 1,5 meter.', 'English Channel eastern part': 'north 3 to 4, shifting northeast, for a time increasing \\n5, at times shower squalls, sea increasing 1 meter.', 'IJsselmeer': 'northwest 3, shifting north, increasing 4, locally 5, \\nlocally shower squalls, sea 0,5 meter.'})\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:33:01.439256Z",
     "start_time": "2025-03-12T20:33:01.432257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "forecast_json = json.dumps(forecast.to_dict())\n",
    "forecast_from_json = Forecast.from_dict(json.loads(forecast_json))\n",
    "forecast == forecast_from_json"
   ],
   "id": "f2485450ef224fa1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T20:36:18.523356Z",
     "start_time": "2025-03-12T20:36:15.472503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "tg_token = os.environ[\"TOKEN\"]\n",
    "cloudflare_account_id = os.environ.get(\"CF_ACC_ID\")\n",
    "cloudflare_database_id = os.environ.get(\"CF_DB_ID\")\n",
    "cloudflare_token_id = os.environ.get(\"CF_TOKEN\")\n",
    "storage = CloudflareD1Storage(cloudflare_account_id, cloudflare_database_id, cloudflare_token_id)\n",
    "ForecastNotifier(forecast_from_json, storage, tg_token).notify()"
   ],
   "id": "2fce830b12470327",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5d2dd3c952c02813"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
