{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Shipping Forecast Bot Prototype",
   "id": "e78c59b1b9bcae28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preinstall the required packages",
   "id": "2414fee7ca43539e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T19:25:19.361965Z",
     "start_time": "2025-03-11T19:25:17.578705Z"
    }
   },
   "source": "!pip install requests beautifulsoup4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (2.32.3)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.9/site-packages (4.13.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests) (2025.1.31)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4) (2.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./venv/lib/python3.9/site-packages (from beautifulsoup4) (4.12.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the data class for the forecast",
   "id": "9d35c1bd10a956ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T19:45:38.795208Z",
     "start_time": "2025-03-11T19:45:38.786012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Forecast:\n",
    "    source_name: str\n",
    "    url: str\n",
    "    publication_time: str\n",
    "    synoptic_info: str\n",
    "    warnings: List[dict]\n",
    "    forecast_details: dict\n",
    "\n",
    "    def display_info(self):\n",
    "        return f\"Forecast published at {self.publication_time} on {self.source_name}\"\n",
    "\n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: dict):\n",
    "        return cls(\n",
    "            source_name=data[\"source_name\"],\n",
    "            url=data[\"url\"],\n",
    "            publication_time=data[\"publication_time\"],\n",
    "            synoptic_info=data[\"synoptic_info\"],\n",
    "            warnings=data[\"warnings\"],\n",
    "            forecast_details=data[\"forecast_details\"]\n",
    "        )\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Forecast):\n",
    "            return False\n",
    "        return self.to_dict() == other.to_dict()\n"
   ],
   "id": "89587bd476ec2771",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the report generator class",
   "id": "ecb09504f77cc261"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T19:35:30.721821Z",
     "start_time": "2025-03-11T19:35:30.710712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReportGenerator:\n",
    "\n",
    "    def __init__(self, forecast: Forecast):\n",
    "        self.forecast = forecast\n",
    "\n",
    "    def generate_report(self, subscribed_areas) -> str:\n",
    "        report_lines = [\n",
    "            f\"Forecast Publication Time: {self.forecast.publication_time}\\n\",\n",
    "            f\"General Synoptic Information: {self.forecast.synoptic_info}\\n\"\n",
    "        ]\n",
    "\n",
    "        # Warnings: include warnings only if any of the affected areas contain one of the user's subscribed areas.\n",
    "        relevant_warnings = []\n",
    "        for warning in self.forecast.warnings:\n",
    "            for warning_area in warning.get(\"areas\", []):\n",
    "                for area in subscribed_areas:\n",
    "                    if area.lower() in warning_area.lower():\n",
    "                        relevant_warnings.append(warning)\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "\n",
    "        if relevant_warnings:\n",
    "            report_lines.append(\"Warnings:\")\n",
    "            for warning in relevant_warnings:\n",
    "                report_lines.append(f\"  Warning Type: {warning.get('warning_type', 'N/A')}\")\n",
    "                report_lines.append(\"  Affected Areas:\")\n",
    "                for w_area in warning.get(\"areas\", []):\n",
    "                    report_lines.append(f\"    - {w_area}\")\n",
    "                report_lines.append(\"\")  # blank line for readability\n",
    "        else:\n",
    "            report_lines.append(\"No warnings for your subscribed areas.\\n\")\n",
    "\n",
    "        # Forecasts for each of the user's areas\n",
    "        report_lines.append(\"Forecasts for your subscribed areas:\")\n",
    "        for user_area in subscribed_areas:\n",
    "            found = False\n",
    "            for region, forecast in self.forecast.forecast_details.items():\n",
    "                # Check if the user's area is present in the forecast region name (case-insensitive)\n",
    "                if user_area.lower() in region.lower():\n",
    "                    report_lines.append(f\"{region}:\")\n",
    "                    report_lines.append(forecast)\n",
    "                    report_lines.append(\"\")  # add a blank line between regions\n",
    "                    found = True\n",
    "            if not found:\n",
    "                report_lines.append(f\"{user_area}: Forecast not found.\\n\")\n",
    "\n",
    "        report_lines.append(f\"Source: {self.forecast.url}\\n\")\n",
    "        return \"\\n\".join(report_lines)"
   ],
   "id": "e0330860e1b30e4d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the DWDParser class",
   "id": "6bc43634a6748d90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T19:25:26.767600Z",
     "start_time": "2025-03-11T19:25:26.691899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import re\n",
    "\n",
    "class DWDParser:\n",
    "\n",
    "    def __init__(self, url=\"https://www.dwd.de/EN/ourservices/seewetternordostseeen/seewetternordostsee.html\"):\n",
    "        # Name of the source\n",
    "        self.name = \"DWD\"\n",
    "        # URL of the web page with forecasts from the German Weather Service\n",
    "        self.url = url\n",
    "        # Send a GET request to fetch the page content\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "        }\n",
    "        self.response = requests.get(url, headers=headers)\n",
    "        # Check if the request was successful\n",
    "        if self.response.status_code != 200:\n",
    "            raise ValueError(f\"Failed to download the page. Status code: {self.response.status_code}\")\n",
    "\n",
    "    def get_forecast(self) -> Forecast:\n",
    "        # Get the HTML content\n",
    "        html_content = self.response.text\n",
    "        # Parse the full HTML document\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        # Find the <pre> tag which contains the bulletin text\n",
    "        pre_tag = soup.find(\"pre\")\n",
    "        if not pre_tag:\n",
    "            raise ValueError(\"No <pre> tag found in the HTML.\")\n",
    "        # Get the plain text (for publication time, synoptic info, and warnings)\n",
    "        pre_text = pre_tag.get_text(separator=\"\\n\")\n",
    "        # Also keep the HTML of the pre tag to leverage the bold (<B>) tags for forecast areas.\n",
    "        pre_html = str(pre_tag)\n",
    "        pre_soup = BeautifulSoup(pre_html, \"html.parser\")\n",
    "        # --- 1. Extract Publication Time ---\n",
    "        # Look for a date/time pattern like \"10.03.2025, 15.36 UTC\"\n",
    "        pub_time_match = re.search(r\"(\\d{2}\\.\\d{2}\\.\\d{4},\\s*\\d{2}\\.\\d{2}\\s*UTC)\", pre_text)\n",
    "        publication_time = pub_time_match.group(1) if pub_time_match else \"Not found\"\n",
    "        # --- 2. Extract General Synoptic Information ---\n",
    "        # We look for the line after the bold header \"General synoptic situation\"\n",
    "        synoptic_info_lines = []\n",
    "        lines = pre_text.splitlines()\n",
    "        synoptic_flag = False\n",
    "        for line in lines:\n",
    "            if \"general synoptic situation\" in line.lower():\n",
    "                synoptic_flag = True\n",
    "                continue\n",
    "            if synoptic_flag:\n",
    "                # Stop if we hit a blank line or a line that likely begins a new section (e.g. warnings)\n",
    "                if line.strip().lower().startswith(\"forecast valid\") or line.strip().lower().startswith(\"until\"):\n",
    "                    break\n",
    "                synoptic_info_lines.append(line.strip())\n",
    "        synoptic_info = \" \".join(synoptic_info_lines)\n",
    "        # --- 3. Extract Warnings Information (e.g. gales, strong winds) ---\n",
    "        # The warnings are given in lines that start with \"until ... in the following forecast areas ... are expected:\"\n",
    "        warnings = []\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            line = lines[i].strip()\n",
    "            # Check for a warning header line using a case-insensitive match\n",
    "            if line.lower().startswith(\"until\"):\n",
    "                # Persist the valid period and the warning type\n",
    "                warning_type = line\n",
    "                if lines[i+1].strip().lower().endswith(\"expected:\"):\n",
    "                    i += 1\n",
    "                    line = lines[i].strip()\n",
    "                    warning_type += \" \" + line\n",
    "                if line.lower().endswith(\"expected:\"):\n",
    "                    # Collect subsequent lines as warning areas until a blank line or another section starts\n",
    "                    warning_areas = []\n",
    "                    i += 1\n",
    "                    while i < len(lines):\n",
    "                        next_line = lines[i].strip()\n",
    "                        if next_line == \"\" or next_line.lower().startswith(\"until\") or next_line.startswith(\"<B>\"):\n",
    "                            break\n",
    "                        warning_areas.append(next_line)\n",
    "                        i += 1\n",
    "\n",
    "                    warnings.append({\n",
    "                        \"warning_type\": warning_type,\n",
    "                        \"areas\": warning_areas\n",
    "                    })\n",
    "            else:\n",
    "                i += 1\n",
    "        # --- 4. Extract Forecast Details for Each Region ---\n",
    "        # We only consider forecast areas that are marked with bold (<B>) tags,\n",
    "        # and skip any sections related to the outlook forecast.\n",
    "        forecast_header = pre_soup.find(lambda tag: tag.name == \"b\" and \"forecast valid until\" in tag.get_text().lower())\n",
    "        forecast_details = {}\n",
    "        if forecast_header:\n",
    "            # Iterate over all <b> tags that come after the forecast header.\n",
    "            for bold_tag in forecast_header.find_all_next(\"b\"):\n",
    "                bold_text = bold_tag.get_text(strip=True)\n",
    "                # Skip any forecast section that is part of the outlook\n",
    "                if \"outlook\" in bold_text.lower():\n",
    "                    break\n",
    "                # Process only forecast areas: they should end with a colon (e.g., \"German Bight:\")\n",
    "                if not bold_text.endswith(\":\"):\n",
    "                    continue\n",
    "                region = bold_text[:-1].strip()  # Remove the trailing colon\n",
    "\n",
    "                # To avoid duplicates, skip if the region is already present.\n",
    "                if region in forecast_details:\n",
    "                    continue\n",
    "\n",
    "                # Collect all following text (from sibling nodes) until the next bold tag is encountered.\n",
    "                forecast_info = \"\"\n",
    "                for sibling in bold_tag.next_siblings:\n",
    "                    # Stop at the next bold tag, which indicates the start of the next forecast area.\n",
    "                    if getattr(sibling, \"name\", None) == \"b\":\n",
    "                        break\n",
    "                    if isinstance(sibling, NavigableString):\n",
    "                        forecast_info += sibling.strip() + \" \"\n",
    "                    else:\n",
    "                        forecast_info += sibling.get_text(\" \", strip=True) + \" \"\n",
    "                forecast_details[region] = forecast_info.strip()\n",
    "        # return results as a Forecast object\n",
    "        return Forecast(\n",
    "            source_name=self.name,\n",
    "            url=self.url,\n",
    "            publication_time=publication_time,\n",
    "            synoptic_info=synoptic_info,\n",
    "            warnings=warnings,\n",
    "            forecast_details=forecast_details\n",
    "        )"
   ],
   "id": "ab1afbca192ab028",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the ForecastNotifier class",
   "id": "55053032e5240f30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T19:36:19.879804Z",
     "start_time": "2025-03-11T19:36:19.871723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "class ForecastNotifier:\n",
    "\n",
    "    def __init__(self, forecast: Forecast):\n",
    "        self.forecast = forecast\n",
    "\n",
    "    def notify(self, subscribed_areas, token, chat_id):\n",
    "        report_generator = ReportGenerator(self.forecast)\n",
    "        report = report_generator.generate_report(subscribed_areas)\n",
    "        telegram_send_url = f\"https://api.telegram.org/bot{token}/sendMessage?chat_id={chat_id}&text={report}\"\n",
    "        return {\"body\": requests.get(telegram_send_url).json()}"
   ],
   "id": "994f5a65de2d5e6",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test the pipeline",
   "id": "1da6ed65c6eb98d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T19:45:59.742070Z",
     "start_time": "2025-03-11T19:45:59.384559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "forecast = DWDParser().get_forecast()\n",
    "print(forecast)"
   ],
   "id": "ac91179866afaabc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast(source_name='DWD', url='https://www.dwd.de/EN/ourservices/seewetternordostseeen/seewetternordostsee.html', publication_time='11.03.2025, 17.01 UTC', synoptic_info=' The northern part of a trough 995 between the Barents Sea, the Baltic States and Austria will move eastwards, allowing a shallow high 1010 over northern Sweden to expand eastwards on Wednesday. A weak low 1000 over Denmark will deepen a little, while a low 1001 Haltenbank will slowly move southwards and weaken a little. A high 1026 Irmingersee weakens, extending a ridge towards the Bay of Biscay.   ', warnings=[{'warning_type': 'until wednesday evening in the following forecast areas strong winds are expected:', 'areas': ['fisher', 'viking', 'skagerrak']}], forecast_details={'German Bight': 'northwesterly winds 4 to 5, later increasing a little, at \\ntimes shower squalls, sea northern part later 3 meter.', 'Southwestern North Sea': 'north to northwest 4 to 5, shower squalls, sea humber \\nfirst 2,5 meter.', 'Fisher': 'north to northeast 5 to 6, locally 7, at times misty, \\nnorthern part at times moderate snow, sea increasing 3 \\nmeter.', 'Dogger': 'north to northwest 4 to 5, later decreasing a little, at \\ntimes shower squalls, sea at times 4 meter.', 'Forties': 'north to northwest about 5, at times shower squalls, sea \\nat times 4 meter.', 'Viking': 'northerly winds 5 to 6, eastern part first 4, at times \\nshower squalls sea at times 4 meter.', 'Utsira': 'utsire:\\nfirst light and variable winds, otherwise northeasterly \\nwinds 4 to 5, at times shower squalls, at times fog \\npatches, sea later 3 meter.', 'Skagerrak': 'northeast 4 to 5, increasing 6, at times misty with \\nmoderate snow, sea increasing 2,5 meter.', 'Kattegat': 'southeasterly winds 3 to 4, for a time increasing about \\n5, at times misty, shower squalls, sea for a time 1 meter.', 'Belts and Sound': 'southerly winds about 3, for a time increasing a little, \\nat times misty, shower squalls, sea 0,5 meter.', 'Western Baltic': 'first light and variable winds, otherwise southwest 3 to \\n4, at times misty, sea 0,5 meter.', 'Southern Baltic': 'easterly winds 3 to 4, shifting southwest later, at times \\nmisty, sea eastern part first 1,5 meter.', 'Boddengewaesser East': 'southeast about 3, shifting southwest, light and variable \\nwinds later, at times misty, sea 0,5 meter.', 'Southeastern Baltic': 'first northeast about 4, otherwise variable directions 2 \\nto 4, sea first 2 meter.', 'Central Baltic': 'northeast 5, shifting slowly east and decreasing a \\nlittle, later variable directions 2 to 4, later misty with \\nsnow squalls, sea at times 1,5 meter.', 'Northern Baltic': 'northeast to east 4 to 5, for a time decreasing a little, \\nat times misty with snow squalls, sea at times 1,5 meter.', 'Gulf of Riga': 'northeast 4, shifting slowly southeast, later abating, \\nsea first 1 meter.', 'English Channel western part': 'northeast 4, shifting slowly north, sea western part 1,5 \\nmeter.', 'English Channel eastern part': 'northeast 4, shifting slowly north, decreasing about 3, \\nsea at times 1 meter.', 'IJsselmeer': 'northwest about 4, for a time shifting west, later \\ndecreasing a little, at times shower squalls, sea for a \\ntime 1 meter.'})\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T19:46:01.738390Z",
     "start_time": "2025-03-11T19:46:01.731531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "forecast_json = json.dumps(forecast.to_dict())\n",
    "forecast_from_json = Forecast.from_dict(json.loads(forecast_json))\n",
    "forecast == forecast_from_json"
   ],
   "id": "f2485450ef224fa1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T19:46:08.283197Z",
     "start_time": "2025-03-11T19:46:08.016671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ForecastNotifier(forecast).notify([\"Western Baltic\"], os.environ[\"TOKEN\"], os.environ[\"CHAT_ID\"])\n",
    "print(\"done\")"
   ],
   "id": "2fce830b12470327",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5d2dd3c952c02813"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
